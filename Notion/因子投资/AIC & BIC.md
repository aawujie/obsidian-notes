---
notion-id: 30178d23-e296-80cd-b8e7-ee64d88ee8c3
base: "[[因子投资.base]]"
Last edited time: 2026-02-11T19:12:00
Tags: []
Verification: unverified
Owner:
  - 杰 吴
---
在模型选择中，**AIC**（赤池信息量准则）和 **BIC**（贝叶斯信息量准则）是你的“指南针”。

简单来说，它们是用来解决同一个问题的：**如何选出一个既能解释数据，又不会过于复杂的模型？**

## 1. 核心逻辑：平衡的艺术

想象你在做一个模型（比如 ARMA）：

- **如果你增加参数（让 p 和 q 变大）**：模型对历史数据的拟合一定会越来越好，误差越来越小。
- **代价是**：模型会变得臃肿，产生**过拟合（Overfitting）**。它记住了历史的噪音，导致对未来预测极差。

AIC 和 BIC 就是用来给模型**打分**的，公式结构非常一致：

- **得分**** = ****模型拟合得有多烂（负似然函数）**** + ****模型的复杂程度（惩罚项）**

**原则：****得分越低越好。**

## 2. 公式拆解

### AIC (Akaike Information Criterion)

$$
AIC = -2 \ln(L) + 2k
$$

- $-2 \ln(L)$：代表拟合程度。**模型拟合越好，**$L$** 越大**，这一项就越小。
- $2k$：**惩罚项**。 **k 是参数个数**（比如 **ARMA(2,1) 的 k=3**）。
- **特点**：**惩罚力度比较温和**。

### BIC (Bayesian Information Criterion)

$$
BIC = -2 \ln(L) + k \ln(n)
$$

- $k \ln(n)$：**更严厉的惩罚项**。n 是样本数量。
- **特点**：由于**样本量 **$n$** 通常很大**，$\ln(n)$** 远大于 2**。所以 BIC 对复杂模型的惩罚比 AIC 狠得多。

## 3. AIC vs BIC：选哪一个？

| **维度** | **AIC** | **BIC** |
| --- | --- | --- |
| **性格** | **慷慨/激进** | **保守/严厉** |
| **偏好** | 倾向于选择**参数多一点、拟合更好**的模型。 | 倾向于选择**结构简单、参数少**的模型。 |
| **风险** | 可能会导致轻微的过拟合。 | 可能会导致模型太简单，漏掉一些规律（欠拟合）。 |
| **适用场景** | 侧重于**预测**（想让预测更准）。 | 侧重于**解释**（想找到最真实简单的规律）。 |

**量化实战建议：**

**在金融时间序列中，因为噪音太多，BIC 通常被认为更稳健**，因为它能强制你选择更简单的模型，防止被历史噪音欺骗。

## 4. 实战用法

当你做 “网格搜索（Grid Search）” 时，你会得到一张热力图。

- **横轴**：$p$ (AR阶数)
- **纵轴**：$q$ (MA阶数)
- **格子里的值**：AIC 或 BIC。

![[image 5.png]]

**操作指南：**

1. 计算 0-5 阶所有组合的 AIC/BIC。
2. 寻找那个数值最小（颜色最浅）的格子。
3. **如果 AIC 选出的是 (5, 4)**，**而 BIC 选出的是 (1, 1)**，**建议折中选择，或者优先信赖 BIC**。

## 5. 总结成一句话

**AIC 和 BIC 就像两个面试官**

**AIC 喜欢全才（哪怕有点虚胖），BIC 喜欢精干的人才（绝对不能有多余脂肪）。**

**在充满噪音的股市数据面前，选那个最 ****“****精干” 的（BIC 最小）通常更安全。**